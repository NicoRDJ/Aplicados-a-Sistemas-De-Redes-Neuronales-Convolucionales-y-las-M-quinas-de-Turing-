# CNN-Turing-Complexity

<div align="center">

![Jerarqu√≠a de Chomsky](https://miro.medium.com/max/1400/1*gBOXRSYG1SerR8BFGq11xQ.png)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.10%2B-red)](https://pytorch.org/)
[![DOI](https://img.shields.io/badge/DOI-10.xxxx%2Fxxxxx-blue)](https://doi.org/)

**Explorando las fronteras te√≥ricas entre Redes Neuronales Convolucionales y la Teor√≠a de la Computabilidad**

</div>

---

## üìö Acerca del Proyecto

Este repositorio contiene la implementaci√≥n del c√≥digo para el art√≠culo **"Fundamentos Matem√°ticos Aplicados a Sistemas De Redes Neuronales Convolucionales y las M√°quinas de Turing"** publicado en la revista EIA. La investigaci√≥n establece conexiones formales entre la profundidad de las CNNs y su capacidad expresiva en t√©rminos de la teor√≠a de la computabilidad.

### üîç Motivaci√≥n

Las redes neuronales profundas han revolucionado el aprendizaje autom√°tico, pero sus fundamentos te√≥ricos en relaci√≥n con modelos computacionales cl√°sicos siguen siendo un √°rea de investigaci√≥n abierta. Este proyecto aborda la pregunta: **¬øExiste una correspondencia entre la profundidad de las redes neuronales y la jerarqu√≠a de Chomsky de complejidad computacional?**

### üî¨ Contribuci√≥n Cient√≠fica

Este trabajo constituye un puente entre dos campos fundamentales:

1. **Aprendizaje Profundo**: Arquitecturas CNN modernas con bloques residuales
2. **Teor√≠a de la Computaci√≥n**: Clases de complejidad computacional seg√∫n la jerarqu√≠a de Chomsky

A trav√©s de experimentos rigurosos y an√°lisis matem√°tico, demostramos que:

- Las CNNs m√°s profundas pueden reconocer patrones de mayor complejidad computacional
- El tiempo de aprendizaje escala con la complejidad te√≥rica del problema
- Existen l√≠mites fundamentales derivados de la teor√≠a de la computabilidad que se manifiestan emp√≠ricamente

## üß† Fundamento Te√≥rico

<div align="center">
<img src="https://miro.medium.com/max/1400/1*i0o8mjFfCn-uD79-F1Cqkw.png" alt="Relaci√≥n entre Profundidad y Complejidad" width="600"/>
</div>

La jerarqu√≠a de Chomsky clasifica los lenguajes formales en cuatro tipos, cada uno correspondiente a un modelo computacional con diferente poder expresivo:

| Tipo | Clase de Lenguaje | Modelo Computacional | Ejemplo | Implementaci√≥n |
|------|-------------------|----------------------|---------|----------------|
| 3 | Regular | Aut√≥mata Finito | a*b* | Patrones regulares |
| 2 | Libre de Contexto | Aut√≥mata con Pila | a^n b^n | Patrones Sierpinski, par√©ntesis balanceados |
| 1 | Sensible al Contexto | Aut√≥mata Limitado Lineal | a^n b^n c^n | Patrones sensibles al contexto |
| 0 | Recursivamente Enumerable | M√°quina de Turing | Problema de la parada | Patrones recursivos generales |

Nuestra hip√≥tesis central es que la profundidad arquitect√≥nica de las CNNs se corresponde con esta jerarqu√≠a, permitiendo que redes m√°s profundas capturen patrones de mayor complejidad computacional.

## üöÄ Caracter√≠sticas

- **Generadores de Patrones**: Implementaci√≥n de generadores para diferentes clases de complejidad
  - Patrones de Sierpinski (recursivos)
  - Patrones de par√©ntesis balanceados (libres de contexto)
  - Patrones sensibles al contexto (a^n b^n c^n)
  - Patrones regulares y de aut√≥matas linealmente acotados
  
- **Arquitectura CNN Avanzada**:
  - Bloques residuales para mejor flujo de gradiente
  - Profundidad configurable para experimentaci√≥n sistem√°tica
  - Normalizaci√≥n por lotes y otras t√©cnicas modernas
  
- **Marco Experimental Completo**:
  - Entrenamiento con validaci√≥n cruzada
  - An√°lisis de rendimiento por clase de complejidad
  - Visualizaci√≥n detallada de resultados

## üõ†Ô∏è Instalaci√≥n

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/CNN-Turing-Complexity.git
cd CNN-Turing-Complexity

# Crear entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

## üìä Uso

### Ejecutar Experimentos

```bash
# Experimento completo con m√∫ltiples profundidades
python scripts/experiment.py --modo completo --num_epocas 30 --profundidades 3 5 7

# Experimento simplificado (r√°pido)
python scripts/experiment.py --modo simplificado --num_epocas 10
```

### Par√°metros Disponibles

| Par√°metro | Descripci√≥n | Valor Predeterminado |
|-----------|-------------|----------------------|
| `--modo` | Modo de experimento (`simplificado` o `completo`) | `simplificado` |
| `--num_muestras` | N√∫mero de muestras en el conjunto de datos | 400 |
| `--tamano_imagen` | Tama√±o de las im√°genes generadas | 64 |
| `--tamano_lote` | Tama√±o del lote para entrenamiento | 32 |
| `--num_epocas` | N√∫mero de √©pocas de entrenamiento | 30 |
| `--tasa_aprendizaje` | Tasa de aprendizaje | 0.001 |
| `--profundidades` | Profundidades de CNN para experimentar | [3, 5, 7] |
| `--semilla` | Semilla aleatoria para reproducibilidad | 42 |
| `--directorio_salida` | Directorio para guardar resultados | `resultados` |
| `--usar_aumento_datos` | Usar aumento de datos para entrenamiento | `False` |
| `--paciencia` | Paciencia para detenci√≥n temprana | 5 |
| `--num_clases` | N√∫mero de clases a utilizar (3-5) | 4 |

### Visualizaci√≥n de Resultados

```bash
# Analizar resultados generados (crea visualizaciones en el directorio de resultados)
python scripts/visualize_results.py --directorio_resultados resultados
```

## üìà Resultados

<div align="center">
<img src="https://miro.medium.com/max/1400/1*gZ4m2DAz6dlGXKGRrE7o3g.jpeg" alt="Resultados Experimentales" width="700"/>
</div>

Nuestros experimentos muestran una clara correlaci√≥n entre la profundidad de la CNN y su capacidad para reconocer patrones de diferentes complejidades computacionales:

- **CNNs superficiales (profundidad 3)**: Excelente rendimiento en patrones regulares (Tipo 3), pero rendimiento limitado en patrones m√°s complejos
- **CNNs intermedias (profundidad 5)**: Buena capacidad para reconocer patrones libres de contexto (Tipo 2)
- **CNNs profundas (profundidad 7+)**: Capacidad para reconocer incluso patrones sensibles al contexto (Tipo 1)

Los tiempos de entrenamiento tambi√©n escalan con la complejidad te√≥rica, validando nuestra hip√≥tesis sobre la relaci√≥n entre recursos computacionales y complejidad.

## üìù Publicaci√≥n Asociada

Si utilizas este c√≥digo en tu investigaci√≥n, por favor cita nuestro art√≠culo:

```bibtex
@article{rodriguez2023fundamentos,
  title={Fundamentos Matem√°ticos Aplicados a Sistemas De Redes Neuronales Convolucionales y las M√°quinas de Turing},
  author={Rodr√≠guez D√≠az, Nicol√°s},
  journal={Revista EIA},
  year={2023}
}
```

## ü§ù Contribuciones

Las contribuciones son bienvenidas y apreciadas. Aqu√≠ hay algunas formas de contribuir:

- üêõ Reportar bugs y problemas
- üí° Proponer nuevas caracter√≠sticas o mejoras
- üìö Mejorar la documentaci√≥n
- üß™ Agregar m√°s pruebas
- üîç Revisar pull requests

Para contribuir:

1. Haz fork del proyecto
2. Crea una rama para tu contribuci√≥n (`git checkout -b feature/nueva-funcionalidad`)
3. Haz commit de tus cambios (`git commit -m 'Agrega nueva funcionalidad'`)
4. Haz push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para m√°s detalles.

## üìß Contacto

Nicol√°s Rodr√≠guez D√≠az - [nrodrigued@eafit.edu.co](mailto:nrodrigued@eafit.edu.co)

Universidad EAFIT, Medell√≠n, Colombia

---

<div align="center">
<p>
<a href="https://github.com/tu-usuario/CNN-Turing-Complexity/stargazers">‚≠ê Dame una estrella si te resulta √∫til! ‚≠ê</a>
</p>

<p>
<b>Una investigaci√≥n en la intersecci√≥n del Aprendizaje Profundo y la Teor√≠a de la Computaci√≥n</b>
</p>
</div>
